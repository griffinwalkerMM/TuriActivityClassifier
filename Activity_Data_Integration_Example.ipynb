{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Activity Data Integration**\n",
    "This notebook is intended to show you how you might train your own model over some activity data. In this example, we took some data from [Viktor Malyi's 4 part article](https://towardsdatascience.com/run-or-walk-detecting-user-activity-with-machine-learning-and-core-ml-part-1-9658c0dcdd90) and formatted it such that the TuriCreate activity classifier function could accept it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: You are using MXNet 1.3.0 which may result in breaking behavior.\n",
      "         To fix this, please install the currently recommended version:\n",
      "\n",
      "             pip uninstall -y mxnet && pip install mxnet==1.1.0\n",
      "\n",
      "         If you want to use a CUDA GPU, then change 'mxnet' to 'mxnet-cu90' (adjust 'cu90' depending on your CUDA version):\n",
      "\n",
      "2018-11-21 18:22:38,979 - skafossdk.data_engine - INFO - Connecting to DataEngine\n",
      "2018-11-21 18:22:39,275 - skafossdk.data_engine - INFO - DataEngine Connection Opened\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import turicreate as tc\n",
    "import io\n",
    "import requests\n",
    "from skafossdk import *\n",
    "\n",
    "ska = Skafos()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Read the Data**\n",
    "For simplicity, we loaded the data into an S3 bucket but the original source is [Viktor Malyi's Kaggle submission](https://www.kaggle.com/vmalyi/run-or-walk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "req = requests.get(\"https://s3.amazonaws.com/skafos.example.data/running_walking.csv\")\n",
    "s = req.content\n",
    "dat = pd.read_csv(io.StringIO(s.decode('utf-8')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data Cleaning**\n",
    "We do some basic data cleaning to get it in a format for the Turi Create function to accept.\n",
    "\n",
    "- The major requirements for the Turi Create function are a session_id and activity label.\n",
    "- A session can be thought of as an experiment where the data is being collected on just one activity type. \n",
    "\n",
    "Because we have timestamps and not session ids, we try to back into a session column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not necessary but for ease of interpretation, map the activities to names\n",
    "activity_map = {1 : 'running', 0: 'walking'}\n",
    "\n",
    "# clean up the date time field\n",
    "dat['time'] = dat['time'].astype(str).apply(lambda x: \":\".join(x.split(\":\")[0:3]))\n",
    "dat['date_time'] = dat['date'] + \" \" + dat['time']\n",
    "dat['date_time'] = dat['date_time'].apply(lambda x: datetime.strptime(x, \"%Y-%m-%d %H:%M:%S\"))\n",
    "\n",
    "# map the activities to names\n",
    "dat['activity'] = dat['activity'].apply(lambda x: activity_map[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The below is a function that:\n",
    "- takes as input a dataframe\n",
    "- a time column name ( of type **`datetime`** or in the pandas world **`pandas._libs.tslibs.timestamps.Timestamp`** )\n",
    "- an activity column name\n",
    "- returns the same dataframe with a 'session_id' column.\n",
    "\n",
    "The function takes each row and assigns it a session based on how soon that record was timestamped after the previous record (controlling for actvity type)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_session_ids(df, time_col, activity_col, threshold = 10):\n",
    "    \n",
    "    # sort the dataframe by activity and time, add an index column\n",
    "    temp_df = df.sort_values(by = [activity_col, time_col]).reset_index(drop = False)\n",
    "    \n",
    "    # create a list of index, time, activity objects\n",
    "    recs = list(temp_df.apply(lambda x: {'index' : x['index'], time_col :  x[time_col], activity_col : x[activity_col]}, axis = 1))\n",
    "    sessions = []; session_id = 0\n",
    "    # loop over the time, activity objects, assign \"session ids\" to those records that are within the time threshold\n",
    "    for i in range(len(recs)):\n",
    "        if (recs[i][time_col] - recs[i-1][time_col]).total_seconds() < threshold and recs[i][activity_col] == recs[i-1][activity_col]:\n",
    "            recs[i]['session_id'] = session_id\n",
    "            sessions.append(recs[i])\n",
    "        else:\n",
    "            session_id +=1 # up the session id\n",
    "            recs[i]['session_id'] = session_id\n",
    "            sessions.append(recs[i])\n",
    "    \n",
    "    # convert back to df, merge with original df \n",
    "    session_df = pd.DataFrame.from_records(sessions)\n",
    "    merged_df = pd.merge(temp_df, session_df, on = ['index', time_col, activity_col], how = 'left')\n",
    "    \n",
    "    # clean up the dataframe\n",
    "    del merged_df['index']\n",
    "    \n",
    "    return merged_df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Here we generate the session ids and assign it back to the variable **`dat`**. \n",
    "- Finally we convert to an **`SFrame`**, the a TuriCreate data type similar to pandas dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data has dimensions (88588, 8)\n"
     ]
    }
   ],
   "source": [
    "dat = generate_session_ids(dat, 'date_time', 'activity')\n",
    "dat = dat[['session_id', 'activity', 'acceleration_x', 'acceleration_y', 'acceleration_z', 'gyro_x', 'gyro_y', 'gyro_z']]\n",
    "print(f\"The data has dimensions {dat.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the distribution of the sessions across activity type\n",
    "print(\"The Distribution of Sessions across activity type are as follows ... \\n \")\n",
    "dat.groupby(['activity']).agg({'session_id' : pd.Series.nunique})/dat['session_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample sessions from the dataframe\n",
    "unique_sessions = len(dat['session_id'].unique())\n",
    "n_session_samples = int(unique_sessions * 0.5)\n",
    "print(f\"There are {unique_sessions} sessions\")\n",
    "print(f\"Sampling {n_session_samples} sessions due to memory constraints\")\n",
    "session_sample = pd.Series(dat['session_id'].unique()).sample(n_session_samples)\n",
    "\n",
    "# assign the sampled df back to itself\n",
    "sample_dat = dat[dat['session_id'].isin(session_sample)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The Distribution of Sampled Sessions across activity type are as follows ... \\n \")\n",
    "sample_dat.groupby(['activity']).agg({'session_id' : pd.Series.nunique})/sample_dat['session_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to SFrame because that's what Turi Create needs\n",
    "dat = tc.SFrame(dat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Train the Model**\n",
    "\n",
    "The following is the same code as in the example. We have replaced the session_id argument and target argument with the appropriate column names in our new dataframe.\n",
    "\n",
    "Steps:\n",
    "- Split into training and testing\n",
    "- Create the model (model build)\n",
    "- Evaluate the model on the testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = tc.activity_classifier.util.random_split_by_session(dat, session_id='session_id',\n",
    "                                                                  fraction=0.8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tc.activity_classifier.create(train, session_id='session_id', target='activity',\n",
    "                                      prediction_window=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = model.evaluate(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
