{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Activity Data Integration**\n",
    "This notebook is intended to show you how you might train your own model over some activity data. In this example, we took some data from [Viktor Malyi's 4 part article](https://towardsdatascience.com/run-or-walk-detecting-user-activity-with-machine-learning-and-core-ml-part-1-9658c0dcdd90) and formatted it such that the TuriCreate activity classifier function could accept it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import turicreate as tc\n",
    "from s3fs.core import S3FileSystem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Read the Data**\n",
    "For simplicity, we loaded the data into an S3 bucket but the original source is [Viktor Malyi's Kaggle submission](https://www.kaggle.com/vmalyi/run-or-walk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = S3FileSystem(anon= True)\n",
    "file = s3.open(\"s3://skafos.example.data/running_walking.csv\", \"rb\")\n",
    "dat = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data Cleaning**\n",
    "We do some basic data cleaning to get it in a format for the Turi Create function to accept.\n",
    "\n",
    "- The major requirements for the Turi Create function are a session_id and activity label.\n",
    "- A session can be thought of as an experiment where the data is being collected on just one activity type. \n",
    "\n",
    "Because we have timestamps and not session ids, we try to back into a session column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not necessary but for ease of interpretation, map the activities to names\n",
    "activity_map = {1 : 'running', 0: 'walking'}\n",
    "\n",
    "# clean up the date time field\n",
    "dat['time'] = dat['time'].astype(str).apply(lambda x: \":\".join(x.split(\":\")[0:3]))\n",
    "dat['date_time'] = dat['date'] + \" \" + dat['time']\n",
    "dat['date_time'] = dat['date_time'].apply(lambda x: datetime.strptime(x, \"%Y-%m-%d %H:%M:%S\"))\n",
    "\n",
    "# map the activities to names\n",
    "dat['activity'] = dat['activity'].apply(lambda x: activity_map[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The below is a function that:\n",
    "- takes as input a dataframe\n",
    "- a time column name ( of type **`datetime`** or in the pandas world **`pandas._libs.tslibs.timestamps.Timestamp`** )\n",
    "- an activity column name\n",
    "- returns the same dataframe with a 'session_id' column.\n",
    "\n",
    "The function takes each row and assigns it a session based on how soon that record was timestamped after the previous record (controlling for actvity type)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_session_ids(df, time_col, activity_col, threshold = 10):\n",
    "    \n",
    "    # sort the dataframe by activity and time, add an index column\n",
    "    temp_df = df.sort_values(by = [activity_col, time_col]).reset_index(drop = False)\n",
    "    \n",
    "    # create a list of index, time, activity objects\n",
    "    recs = list(temp_df.apply(lambda x: {'index' : x['index'], time_col :  x[time_col], activity_col : x[activity_col]}, axis = 1))\n",
    "    sessions = []; session_id = 0\n",
    "    # loop over the time, activity objects, assign \"session ids\" to those records that are within the time threshold\n",
    "    for i in range(len(recs)):\n",
    "        if (recs[i][time_col] - recs[i-1][time_col]).total_seconds() < threshold and recs[i][activity_col] == recs[i-1][activity_col]:\n",
    "            recs[i]['session_id'] = session_id\n",
    "            sessions.append(recs[i])\n",
    "        else:\n",
    "            session_id +=1 # up the session id\n",
    "            recs[i]['session_id'] = session_id\n",
    "            sessions.append(recs[i])\n",
    "    \n",
    "    # convert back to df, merge with original df \n",
    "    session_df = pd.DataFrame.from_records(sessions)\n",
    "    merged_df = pd.merge(temp_df, session_df, on = ['index', time_col, activity_col], how = 'left')\n",
    "    \n",
    "    # clean up the dataframe\n",
    "    del merged_df['index']\n",
    "    \n",
    "    return merged_df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Here we generate the session ids and assign it back to the variable **`dat`**. \n",
    "- Finally we convert to an **`SFrame`**, the a TuriCreate data type similar to pandas dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = generate_session_ids(dat, 'date_time', 'activity')\n",
    "dat = dat[['session_id', 'activity', 'acceleration_x', 'acceleration_y', 'acceleration_z', 'gyro_x', 'gyro_y', 'gyro_z']]\n",
    "dat = tc.SFrame(dat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Train the Model**\n",
    "\n",
    "The following is the same code as in the example. We have replaced the session_id argument and target argument with the appropriate column names in our new dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = tc.activity_classifier.util.random_split_by_session(dat, session_id='session_id', fraction=0.8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>Pre-processing 54193 samples...</pre>"
      ],
      "text/plain": [
       "Pre-processing 54193 samples..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Using sequences of size 400 for model creation.</pre>"
      ],
      "text/plain": [
       "Using sequences of size 400 for model creation."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Processed a total of 149 sessions.</pre>"
      ],
      "text/plain": [
       "Processed a total of 149 sessions."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU to create model (CUDA)\n",
      "+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+\n",
      "| Iteration           | Train Accuracy      | Train Loss          | Validation Accuracy | Validation Loss     | Elapsed Time        |\n",
      "+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+\n",
      "| 1                   | 0.463               | 0.854               | 0.611               | 0.400               | 0.1                 | \n",
      "| 2                   | 0.759               | 0.305               | 0.914               | 0.347               | 0.2                 | \n",
      "| 3                   | 0.786               | 0.283               | 1.000               | 0.265               | 0.3                 | \n",
      "| 4                   | 0.853               | 0.206               | 1.000               | 0.163               | 0.3                 | \n",
      "| 5                   | 0.906               | 0.160               | 1.000               | 0.071               | 0.4                 | \n",
      "| 6                   | 0.922               | 0.137               | 1.000               | 0.023               | 0.5                 | \n",
      "| 7                   | 0.933               | 0.121               | 1.000               | 0.008               | 0.6                 | \n",
      "| 8                   | 0.958               | 0.098               | 1.000               | 0.004               | 0.6                 | \n",
      "| 9                   | 0.964               | 0.088               | 1.000               | 0.002               | 0.7                 | \n",
      "| 10                  | 0.963               | 0.080               | 1.000               | 0.001               | 0.8                 | \n",
      "+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+\n",
      "Training complete\n",
      "Total Time Spent: 0.806368s\n"
     ]
    }
   ],
   "source": [
    "model = tc.activity_classifier.create(train, session_id='session_id', target='activity', prediction_window=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = model.evaluate(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 1.0,\n",
       " 'auc': 1.0000000000000058,\n",
       " 'precision': 1.0,\n",
       " 'recall': 1.0,\n",
       " 'f1_score': 1.0,\n",
       " 'log_loss': 0.002604441012345844,\n",
       " 'confusion_matrix': Columns:\n",
       " \ttarget_label\tstr\n",
       " \tpredicted_label\tstr\n",
       " \tcount\tint\n",
       " \n",
       " Rows: 2\n",
       " \n",
       " Data:\n",
       " +--------------+-----------------+-------+\n",
       " | target_label | predicted_label | count |\n",
       " +--------------+-----------------+-------+\n",
       " |   running    |     running     | 16109 |\n",
       " |   walking    |     walking     | 14111 |\n",
       " +--------------+-----------------+-------+\n",
       " [2 rows x 3 columns],\n",
       " 'roc_curve': Columns:\n",
       " \tthreshold\tfloat\n",
       " \tfpr\tfloat\n",
       " \ttpr\tfloat\n",
       " \tp\tint\n",
       " \tn\tint\n",
       " \n",
       " Rows: 100001\n",
       " \n",
       " Data:\n",
       " +-----------+--------------------+-----+-------+-------+\n",
       " | threshold |        fpr         | tpr |   p   |   n   |\n",
       " +-----------+--------------------+-----+-------+-------+\n",
       " |    0.0    |        1.0         | 1.0 | 14111 | 16109 |\n",
       " |   1e-05   | 0.9916816686324414 | 1.0 | 14111 | 16109 |\n",
       " |   2e-05   | 0.9767831646905456 | 1.0 | 14111 | 16109 |\n",
       " |   3e-05   | 0.950710782792228  | 1.0 | 14111 | 16109 |\n",
       " |   4e-05   | 0.940778446830964  | 1.0 | 14111 | 16109 |\n",
       " |   5e-05   | 0.9159476069278043 | 1.0 | 14111 | 16109 |\n",
       " |   6e-05   | 0.8988143273946241 | 1.0 | 14111 | 16109 |\n",
       " |   7e-05   | 0.8777081134769383 | 1.0 | 14111 | 16109 |\n",
       " |   8e-05   | 0.8590849835495685 | 1.0 | 14111 | 16109 |\n",
       " |   9e-05   | 0.8503941895834627 | 1.0 | 14111 | 16109 |\n",
       " +-----------+--------------------+-----+-------+-------+\n",
       " [100001 rows x 5 columns]\n",
       " Note: Only the head of the SFrame is printed.\n",
       " You can use print_rows(num_rows=m, num_columns=n) to print more rows and columns.}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
